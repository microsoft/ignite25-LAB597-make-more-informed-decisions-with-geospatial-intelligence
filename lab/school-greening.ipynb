{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d58179b-2eb4-4384-88f1-b89d6eb478d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LAB 597: Make More Informed Decisions with Geospatial Intelligence\n",
    "\n",
    "Welcome! In this lab you will take your first steps with geospatial data and see how satellite imagery can answer a real community question: *How hot are school campuses, and how might greening help?* You do **not** need prior GIS or remote sensing experience—each concept is introduced briefly and applied immediately.\n",
    "\n",
    "\n",
    "\n",
    "## What Is Geospatial Data?\n",
    "\n",
    "Geospatial data is any information tied to a location on Earth. Instead of just rows and columns, we also have shapes (points, lines, polygons) or pixels that map to latitude/longitude. Examples:\n",
    "\n",
    "- A point: the centroid of a school\n",
    "\n",
    "- A polygon: the outline (footprint) of a campus\n",
    "\n",
    "- A raster (grid): a satellite image where each pixel stores a value (like temperature or vegetation)\n",
    "\n",
    "\n",
    "\n",
    "By combining these, we can ask location-based questions: Which schools have the least vegetation? Which campuses run hottest in summer? Where should we prioritize cooling investments?\n",
    "\n",
    "\n",
    "\n",
    "## Microsoft Planetary Computer (MPC)\n",
    "\n",
    "The Microsoft Planetary Computer hosts curated, analysis-ready environmental datasets (imagery, climate layers, elevation, land cover, and more) and provides APIs + scalable infrastructure so you can:\n",
    "\n",
    "1. Discover trusted geospatial datasets via STAC (a common catalog standard)\n",
    "\n",
    "2. Access them efficiently as Cloud-Optimized GeoTIFFs (stream only the pixels you need)\n",
    "\n",
    "3. Combine multiple data sources to solve real-world sustainability and resilience problems\n",
    "\n",
    "\n",
    "\n",
    "In this lab we will use MPC to pull:\n",
    "\n",
    "- **NAIP aerial imagery** for a clear visual + vegetation (NDVI) indicator\n",
    "\n",
    "- **Landsat thermal data** for land surface temperature (LST)\n",
    "\n",
    "\n",
    "\n",
    "## The Basic Analysis Workflow\n",
    "\n",
    "This lab mirrors a repeatable pattern used in geospatial analytics at larger scales:\n",
    "\n",
    "1. **Identify facilities (areas) of interest** – We load all school footprints and select one pilot campus.\n",
    "\n",
    "2. **Gather the required data** – Query MPC for imagery (NAIP) and temperature (Landsat) that intersect the campus.\n",
    "\n",
    "3. **Run a model or calculation** – Compute vegetation (NDVI) and mean land surface temperature from clipped pixels, applying quality masks.\n",
    "\n",
    "4. **Present findings** – Summarize and visualize: How does temperature vary across multiple summer observations? What might that imply for greening strategies?\n",
    "\n",
    "\n",
    "\n",
    "> At enterprise or “planetary” scale the exact same pattern applies—you just automate it across thousands of sites and many time periods, then store aggregated metrics for decision-makers.\n",
    "\n",
    "\n",
    "\n",
    "## What You Will Do Here\n",
    "\n",
    "- Load and inspect a school footprint dataset\n",
    "\n",
    "- Clip high‑resolution imagery and thermal pixels to a single campus\n",
    "\n",
    "- Calculate NDVI (vegetation index) and mean land surface temperature\n",
    "\n",
    "- Explore multiple summer observations to understand temporal variation\n",
    "\n",
    "\n",
    "\n",
    "## Why It Matters\n",
    "\n",
    "Urban heat and equitable access to cool, green spaces are public health issues. Geospatial intelligence transforms raw pixels into actionable metrics that help communities decide **where** to invest and **why**.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7c80716-edd1-43b9-9572-3dcf6c1c95f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, we will import some function into memory and make them available for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "40aa48d1-e0e6-46fd-a8cc-a2e0f0472c95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, Callable, TypeVar, Union\n",
    "\n",
    "import azure.core.credentials\n",
    "import azure.identity\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "import httpx\n",
    "import planetary_computer as pc\n",
    "import pystac\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from pyproj import Transformer\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import transform\n",
    "from rasterio.mask import mask\n",
    "from zoneinfo import ZoneInfo\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "MPC_APP_ID = \"https://geocatalog.spatio.azure.com\"\n",
    "\n",
    "RequestT = TypeVar(\"RequestT\", bound=Union[requests.Request, httpx.Request])\n",
    "\n",
    "def get_token(credential: azure.core.credentials.TokenCredential, app_id: str) -> str:\n",
    "    return credential.get_token(f\"{app_id}/.default\").token\n",
    "\n",
    "token = sc.broadcast(get_token(azure.identity.ManagedIdentityCredential(), MPC_APP_ID))\n",
    "\n",
    "def token_auth(\n",
    "    credential: azure.core.credentials.TokenCredential, app_id: str\n",
    ") -> Callable[[RequestT], RequestT]:\n",
    "    def _(request: RequestT) -> RequestT:\n",
    "        request.headers[\"Authorization\"] = f\"Bearer {token.value}\"\n",
    "        return request\n",
    "\n",
    "    return _\n",
    "geocatalog_url = \"https://lab597geocatalog.czeteqbrbtb7gzcz.northcentralus.geocatalog.spatio.azure.com/\"\n",
    "openpc = Client.open(\n",
    "    f\"{geocatalog_url}/stac\",\n",
    "    request_modifier=token_auth(azure.identity.ManagedIdentityCredential(), MPC_APP_ID))\n",
    "# openpc = Client.open('https://planetarycomputer.microsoft.com/api/stac/v1', modifier=pc.sign_inplace)\n",
    "\n",
    "def get_collection_sas_token(collection_id: str) -> str:\n",
    "    return requests.get(f\"{geocatalog_url}/sas/token/{collection_id}\", headers={'Authorization': f'Bearer {token.value}'}, params={\"api-version\": \"2025-04-30-preview\"}).json()['token']\n",
    "naip_sas_token = get_collection_sas_token(\"naip\")\n",
    "landsat_sas_token = get_collection_sas_token(\"landsat-c2-l2\")\n",
    "\n",
    "class CampusResult(TypedDict):\n",
    "    valid_pixels: int\n",
    "    mean_temp_c: float\n",
    "    mean_temp_f: float\n",
    "    acquisition_date: datetime.datetime\n",
    "\n",
    "# Helper functions for bounding boxes and STAC search\n",
    "def expand_bounds(bounds: Tuple[float, float, float, float], buffer_degrees: float = 0.0008) -> Tuple[float, float, float, float]:\n",
    "    xmin, ymin, xmax, ymax = bounds\n",
    "    return (xmin - buffer_degrees, ymin - buffer_degrees, xmax + buffer_degrees, ymax + buffer_degrees)\n",
    "\n",
    "def most_recent_openpc_item(collection: str, bbox: Tuple[float, float, float, float], start: str, end: str, **search_kwargs):\n",
    "    \"\"\"Return the most recent STAC item intersecting the bbox and date range.\"\"\"\n",
    "    search_parameters = {\n",
    "        'collections': [collection],\n",
    "        'bbox': bbox,\n",
    "        'datetime': f\"{start}/{end}\",\n",
    "        'max_items': search_kwargs.pop('max_items', 20),\n",
    "        'limit': search_kwargs.pop('limit', 20),\n",
    "        'sortby': search_kwargs.pop('sortby', [{'field': 'properties.datetime', 'direction': 'desc'}]),\n",
    "    }\n",
    "    search_parameters.update(search_kwargs)\n",
    "    results = openpc.search(**search_parameters).item_collection()\n",
    "    if not results:\n",
    "        raise ValueError(f'No items found for collection={collection} in the requested window.')\n",
    "    return results[0]\n",
    "\n",
    "def display_school_footprint(school: gpd.GeoDataFrame):\n",
    "    # Quick visualization of the pilot school footprint on a tiled basemap\n",
    "    school_shape = school.geometry.iloc[0]\n",
    "    school_centroid = school_shape.centroid\n",
    "    pilot_gdf = gpd.GeoDataFrame({'name': [school.name]}, geometry=[school_shape], crs='EPSG:4326')\n",
    "    pilot_gdf_3857 = pilot_gdf.to_crs(epsg=3857)\n",
    "    pilot_centroid_3857 = pilot_gdf_3857.geometry.centroid.iloc[0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    pilot_gdf_3857.plot(ax=ax, facecolor='#2e8b57', edgecolor='#115533', alpha=0.35, linewidth=2)\n",
    "    ax.scatter(pilot_centroid_3857.x, pilot_centroid_3857.y, color='darkgreen', s=40, label='Campus centroid')\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    ax.set_title(f\"{school.name} campus footprint\", fontsize=12)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_axis_off()\n",
    "    caption = f\"Centroid: {school_centroid.y:.4f}°N, {school_centroid.x:.4f}°E\"\n",
    "    # plt.suptitle('Only the campus polygon is rendered; background tiles provide familiar context.', fontsize=9, y=0.94)\n",
    "    plt.figtext(0.5, 0.02, caption, ha='center', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_school_results(schools: gpd.GeoDataFrame):\n",
    "    # Quick visualization of the pilot school footprint on a tiled basemap\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for idx, row in schools.iterrows():\n",
    "        school = gpd.GeoDataFrame([row], geometry='geometry', crs=schools_gdf.crs)\n",
    "        school_shape = school.geometry.iloc[0]\n",
    "        pilot_gdf = gpd.GeoDataFrame({'name': [school.name]}, geometry=[school_shape], crs='EPSG:4326')\n",
    "        pilot_gdf_3857 = pilot_gdf.to_crs(epsg=3857)\n",
    "        # Use NDVI colormap for mean_ndvi column\n",
    "        mean_ndvi = row.get('mean_ndvi', np.nan)\n",
    "        # Use RdYlGn colormap, vmin=-1, vmax=1, as in display_school_naip_ndvi\n",
    "        cmap = plt.get_cmap('RdYlGn')\n",
    "        color = cmap((mean_ndvi + 1) / 2) if np.isfinite(mean_ndvi) else (0.7, 0.7, 0.7, 0.35)\n",
    "        pilot_gdf_3857.plot(ax=ax, facecolor=color, edgecolor='#115533', alpha=0.35, linewidth=2)\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    ax.set_title(f\"ALl campus footprints\", fontsize=12)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_axis_off()\n",
    "    # plt.suptitle('Only the campus polygon is rendered; background tiles provide familiar context.', fontsize=9, y=0.94)\n",
    "    # plt.figtext(0.5, 0.02, caption, ha='center', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Use COG-friendly windowed read + mask so we download only pixels intersecting the campus\n",
    "def open_clipped_naip(naip_item: pystac.Item, school: gpd.GeoDataFrame) -> xr.DataArray:\n",
    "    naip_asset = naip_item.assets['image']\n",
    "    naip_href_signed = f\"{naip_asset.href}?{naip_sas_token}\" # pc.sign(naip_asset.href)\n",
    "    with rasterio.open(naip_href_signed) as src:\n",
    "        reproj = Transformer.from_crs('EPSG:4326', src.crs, always_xy=True).transform\n",
    "        school_shape = school.geometry.iloc[0]\n",
    "        pilot_shape_src = transform(reproj, school_shape)\n",
    "        clipped_data, clipped_transform = mask(src, [mapping(pilot_shape_src)], crop=True)\n",
    "        clipped_data = clipped_data.astype('float32')\n",
    "        if src.nodata is not None:\n",
    "            clipped_data = np.where(clipped_data == src.nodata, np.nan, clipped_data)\n",
    "        naip_clip = xr.DataArray(\n",
    "            clipped_data,\n",
    "            dims=(\"band\", \"y\", \"x\"),\n",
    "            coords={\"band\": list(src.indexes)},\n",
    "            name=\"naip_rgb\",\n",
    "        ).rio.write_transform(clipped_transform).rio.write_crs(src.crs)\n",
    "    return naip_clip\n",
    "\n",
    "def display_school_naip_visual(naip_item: pystac.Item, school: gpd.GeoDataFrame):\n",
    "    naip_clip = open_clipped_naip(naip_item, school)\n",
    "    # Display a contrast-stretched RGB image so students can recognize the campus\n",
    "    rgb = np.stack([naip_clip.sel(band=i).values for i in (1, 2, 3)], axis=-1)\n",
    "    if np.isfinite(rgb).any():\n",
    "        low, high = np.nanpercentile(rgb[np.isfinite(rgb)], (2, 98))\n",
    "        scale = max(high - low, 1)\n",
    "        rgb_normalized = np.clip((rgb - low) / scale, 0, 1)\n",
    "    else:\n",
    "        rgb_normalized = np.zeros_like(rgb, dtype=\"float32\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(rgb_normalized)\n",
    "    ax.set_title(f\"{school.name} campus (NAIP true color)\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def display_school_naip_ndvi(naip_item: pystac.Item, school: gpd.GeoDataFrame):\n",
    "    naip_clip = open_clipped_naip(naip_item, school)\n",
    "    # Compute NDVI from NAIP (band order: R, G, B, NIR)\n",
    "    red = naip_clip.sel(band=1).astype('float32')\n",
    "    nir = naip_clip.sel(band=4).astype('float32')\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    ndvi = ndvi.where(np.isfinite(ndvi))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    naip_rgb = np.stack([naip_clip.sel(band=i).values for i in (1, 2, 3)])\n",
    "    naip_rgb_plot = np.transpose(naip_rgb, (1, 2, 0))\n",
    "    axes[0].imshow(np.clip(naip_rgb_plot / np.nanmax(naip_rgb_plot), 0, 1))\n",
    "    axes[0].set_title('NAIP RGB (preview)')\n",
    "    axes[0].axis('off')\n",
    "    ndvi_im = axes[1].imshow(ndvi, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "    axes[1].set_title('NDVI')\n",
    "    axes[1].axis('off')\n",
    "    fig.colorbar(ndvi_im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    plt.show()\n",
    "    print(f\"Mean NDVI over campus: {ndvi.mean().item():.3f}\")\n",
    "\n",
    "def compute_mean_ndvi(naip_item: pystac.Item, school: gpd.GeoDataFrame) -> float:\n",
    "    naip_clip = open_clipped_naip(naip_item, school)\n",
    "    red = naip_clip.sel(band=1).astype('float32')\n",
    "    nir = naip_clip.sel(band=4).astype('float32')\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    ndvi = ndvi.where(np.isfinite(ndvi))\n",
    "    return float(ndvi.mean().item())\n",
    "\n",
    "def collect_analysis_items(\n",
    "        school_bounds: Tuple[float, float, float, float],\n",
    "        temporal_start: str = '2023-01-01',\n",
    "        temporal_end : str | None = None,\n",
    ") -> Tuple[pystac.Item, list[pystac.Item]]:\n",
    "    if temporal_end is None:\n",
    "        temporal_end = pd.Timestamp.utcnow().strftime(\"%Y-%m-%d\")\n",
    "    expanded_bounds = expand_bounds(school_bounds)\n",
    "    naip_item = most_recent_openpc_item('naip', expanded_bounds, temporal_start, temporal_end)\n",
    "\n",
    "    landsat_candidates : list[pystac.Item] = []\n",
    "    landsat_asset_skip_log = []\n",
    "\n",
    "    required_common_assets_primary = {\"qa_pixel\"}\n",
    "    primary_lst_candidates_single = (\"ST_B10\", \"ST_B11\", \"lwir\")\n",
    "    fallback_lst_requirements_single = {\"trad\", \"urad\", \"drad\", \"emis\", \"atran\", \"mtl.json\"}\n",
    "\n",
    "    landsat_search = openpc.search(\n",
    "        collections=['landsat-c2-l2'],\n",
    "        bbox=expanded_bounds,\n",
    "        datetime=f\"{temporal_start}/{temporal_end}\",\n",
    "        query={'eo:cloud_cover': {'lt': 20}},\n",
    "        limit=60,\n",
    "        max_items=60,\n",
    "        sortby=[{'field': 'properties.datetime', 'direction': 'desc'}],\n",
    "        fields={'exclude': ['links', 'collection', 'assets.*.alternate']}\n",
    "    )\n",
    "\n",
    "    for candidate in landsat_search.items():\n",
    "        asset_keys = set(candidate.assets.keys())\n",
    "        if not required_common_assets_primary.issubset(asset_keys):\n",
    "            landsat_asset_skip_log.append({\n",
    "                'id': candidate.id,\n",
    "                'datetime': candidate.datetime.isoformat(),\n",
    "                'missing_assets': sorted(required_common_assets_primary - asset_keys)\n",
    "            })\n",
    "            continue\n",
    "        if not any(name in asset_keys for name in primary_lst_candidates_single):\n",
    "            missing_fallback = fallback_lst_requirements_single - asset_keys\n",
    "            if missing_fallback:\n",
    "                landsat_asset_skip_log.append({\n",
    "                    'id': candidate.id,\n",
    "                    'datetime': candidate.datetime.isoformat(),\n",
    "                    'missing_assets': sorted(missing_fallback)\n",
    "                })\n",
    "                continue\n",
    "        landsat_candidates.append(candidate)\n",
    "        if len(landsat_candidates) >= 12:\n",
    "            break\n",
    "\n",
    "    if not landsat_candidates:\n",
    "        if landsat_asset_skip_log:\n",
    "            print(\"No Landsat items with required assets. Sample of missing asset diagnostics:\")\n",
    "            for entry in landsat_asset_skip_log[:10]:\n",
    "                missing_list = ', '.join(entry['missing_assets']) or 'unknown'\n",
    "                print(f\"  - {entry['id']} ({entry['datetime']}): missing {missing_list}\")\n",
    "            if len(landsat_asset_skip_log) > 10:\n",
    "                print(f\"  ...and {len(landsat_asset_skip_log) - 10} more\")\n",
    "        raise ValueError(\"Unable to find Landsat candidates with the required thermal assets in the requested window.\")\n",
    "\n",
    "    return naip_item, landsat_candidates\n",
    "\n",
    "def load_landsat_lst(item, school, clip_crs='EPSG:4326', enforce_limits=(-40.0, 70.0)) -> xr.DataArray:\n",
    "    \"\"\"Load Landsat Collection 2 L2 surface temperature, apply QA masking, and return LST in °C.\n",
    "\n",
    "    The Microsoft Planetary Computer serves Landsat assets as Cloud-Optimized GeoTIFFs (COGs), so we\n",
    "    read only the pixels that intersect the campus footprint using ``rasterio.mask`` instead of\n",
    "    downloading full rasters. We preferentially use the calibrated ``ST_B10``/``ST_B11`` surface\n",
    "    temperature bands. If they are missing, we fall back to the radiative transfer workflow.\n",
    "\n",
    "    ``clip_geoms`` may contain GeoJSON dicts or shapely geometries expressed in ``clip_crs``.\n",
    "    ``enforce_limits`` filters out unreasonable temperatures (defaults to -40°C..70°C).\n",
    "    \"\"\"\n",
    "\n",
    "    school_shape = school.geometry.iloc[0]\n",
    "    clip_geoms = [mapping(school_shape)]\n",
    "    def _to_shapes(geoms):\n",
    "        shapes_out = []\n",
    "        for geom in geoms:\n",
    "            if isinstance(geom, dict):\n",
    "                shapes_out.append(shape(geom))\n",
    "            elif hasattr(geom, \"__geo_interface__\"):\n",
    "                shapes_out.append(shape(geom.__geo_interface__))\n",
    "            else:\n",
    "                shapes_out.append(geom)\n",
    "        return shapes_out\n",
    "\n",
    "    def _scale_and_offset(band_meta):\n",
    "        scale = band_meta.get('scale')\n",
    "        if scale is None:\n",
    "            scales = band_meta.get('scales')\n",
    "            if isinstance(scales, (list, tuple)) and scales:\n",
    "                scale = scales[0]\n",
    "        if scale is None:\n",
    "            scale = 1.0\n",
    "        offset = band_meta.get('offset')\n",
    "        if offset is None:\n",
    "            offsets = band_meta.get('offsets')\n",
    "            if isinstance(offsets, (list, tuple)) and offsets:\n",
    "                offset = offsets[0]\n",
    "        if offset is None:\n",
    "            offset = 0.0\n",
    "        return float(scale), float(offset)\n",
    "\n",
    "    def _read_asset(asset, dtype='float32', fill_value=np.nan):\n",
    "        href = f\"{asset.href}?{landsat_sas_token}\" # pc.sign(asset.href)\n",
    "        clip_shapes = _to_shapes(clip_geoms)\n",
    "        with rasterio.open(href) as src:\n",
    "            src_crs = src.crs\n",
    "            if clip_crs and src_crs and clip_crs != src_crs.to_string():\n",
    "                transformer = Transformer.from_crs(clip_crs, src_crs, always_xy=True)\n",
    "                shapes_native = [transform(transformer.transform, geom) for geom in clip_shapes]\n",
    "            else:\n",
    "                shapes_native = clip_shapes\n",
    "            shapes_geojson = [mapping(geom) for geom in shapes_native]\n",
    "            data, out_transform = mask(src, shapes_geojson, crop=True, filled=False)\n",
    "            mask_arr = np.ma.getmaskarray(data)\n",
    "            data = data.astype(dtype)\n",
    "            if data.shape[0] == 1:\n",
    "                band_data = data[0]\n",
    "                band_mask = mask_arr[0]\n",
    "            else:\n",
    "                band_data = data[0]\n",
    "                band_mask = mask_arr[0]\n",
    "            band_data = np.where(band_mask, fill_value, band_data)\n",
    "            da = xr.DataArray(band_data, dims=(\"y\", \"x\"))\n",
    "            da = da.rio.write_transform(out_transform).rio.write_crs(src_crs)\n",
    "            return da\n",
    "\n",
    "    clip_shapes = _to_shapes(clip_geoms)\n",
    "    if not clip_shapes:\n",
    "        raise ValueError(\"clip_geoms must contain at least one geometry\")\n",
    "\n",
    "    qa_asset = item.assets.get('qa_pixel')\n",
    "    if qa_asset is None:\n",
    "        raise KeyError('qa_pixel asset is required for masking.')\n",
    "    qa = _read_asset(qa_asset, dtype='uint32', fill_value=0)\n",
    "    cloud_mask = (\n",
    "        ((qa & (1 << 1)) != 0)\n",
    "        | ((qa & (1 << 2)) != 0)\n",
    "        | ((qa & (1 << 3)) != 0)\n",
    "        | (((qa >> 4) & 0b11) >= 2)\n",
    "        | (((qa >> 6) & 0b11) >= 2)\n",
    "    )\n",
    "\n",
    "    lst_asset = item.assets.get('ST_B10') or item.assets.get('ST_B11') or item.assets.get('lwir')\n",
    "    lst_kelvin = None\n",
    "    if lst_asset is not None:\n",
    "        lst_da = _read_asset(lst_asset, dtype='float32', fill_value=np.nan)\n",
    "        band_meta = lst_asset.extra_fields.get('raster:bands', [{}])[0]\n",
    "        scale, offset = _scale_and_offset(band_meta)\n",
    "        lst_kelvin = lst_da * scale + offset\n",
    "        lst_kelvin = xr.where(cloud_mask, np.nan, lst_kelvin)\n",
    "\n",
    "    if lst_kelvin is None:\n",
    "        thermal_radiance_keys = ['trad', 'urad', 'drad', 'emis', 'atran']\n",
    "        missing_keys = [key for key in thermal_radiance_keys if key not in item.assets]\n",
    "        if missing_keys:\n",
    "            raise KeyError(f\"Unable to locate LST assets: {', '.join(missing_keys)}\")\n",
    "\n",
    "        clipped_assets = {}\n",
    "        for key in thermal_radiance_keys:\n",
    "            asset = item.assets[key]\n",
    "            band_meta = asset.extra_fields.get('raster:bands', [{}])[0]\n",
    "            scale, offset = _scale_and_offset(band_meta)\n",
    "            da = _read_asset(asset, dtype='float32', fill_value=np.nan)\n",
    "            clipped_assets[key] = da * scale + offset\n",
    "\n",
    "        rad = clipped_assets['trad']\n",
    "        up = clipped_assets['urad']\n",
    "        down = clipped_assets['drad']\n",
    "        emissivity = clipped_assets['emis'].clip(0.0001, 0.9999)\n",
    "        transmittance = clipped_assets['atran'].clip(0.0001)\n",
    "\n",
    "        radiance_surface = (rad - up - (1 - emissivity) * down) / (emissivity * transmittance)\n",
    "        radiance_surface = xr.where((radiance_surface <= 0) | cloud_mask, np.nan, radiance_surface)\n",
    "        # Determine thermal conversion constants\n",
    "        mtl_href = f\"{item.assets['mtl.json'].href}?{landsat_sas_token}\"# pc.sign(item.assets['mtl.json'].href)\n",
    "        mtl_response = requests.get(mtl_href, timeout=30)\n",
    "        mtl_response.raise_for_status()\n",
    "        metadata = mtl_response.json()['LANDSAT_METADATA_FILE']\n",
    "        thermal_constants = metadata.get('LEVEL1_THERMAL_CONSTANTS', {})\n",
    "        band_priority = [\n",
    "            ('K1_CONSTANT_BAND_10', 'K2_CONSTANT_BAND_10'),\n",
    "            ('K1_CONSTANT_BAND_11', 'K2_CONSTANT_BAND_11'),\n",
    "            ('K1_CONSTANT_BAND_6_VCID_1', 'K2_CONSTANT_BAND_6_VCID_1'),\n",
    "            ('K1_CONSTANT_BAND_6_VCID_2', 'K2_CONSTANT_BAND_6_VCID_2'),\n",
    "        ]\n",
    "        k1 = k2 = None\n",
    "        for k1_key, k2_key in band_priority:\n",
    "            if k1_key in thermal_constants and k2_key in thermal_constants:\n",
    "                k1 = float(thermal_constants[k1_key])\n",
    "                k2 = float(thermal_constants[k2_key])\n",
    "                break\n",
    "        if k1 is None or k2 is None:\n",
    "            raise KeyError('Unable to determine thermal conversion parameters for this item')\n",
    "        lst_kelvin = k2 / np.log((k1 / radiance_surface) + 1)\n",
    "\n",
    "    lst_celsius = lst_kelvin - 273.15\n",
    "    lst_celsius = lst_celsius.where(np.isfinite(lst_celsius))\n",
    "    if enforce_limits is not None:\n",
    "        min_c, max_c = enforce_limits\n",
    "        lst_celsius = lst_celsius.where((lst_celsius >= min_c) & (lst_celsius <= max_c))\n",
    "    return lst_celsius\n",
    "\n",
    "def landsat_item_has_required_assets(item: pystac.Item) -> Tuple[bool, dict | None]:\n",
    "    required_common_assets = {\"qa_pixel\"}\n",
    "    primary_lst_candidates = (\"ST_B10\", \"ST_B11\", \"lwir\")\n",
    "    fallback_lst_requirements = {\"trad\", \"urad\", \"drad\", \"emis\", \"atran\", \"mtl.json\"}\n",
    "    asset_keys = set(item.assets.keys())\n",
    "    if not required_common_assets.issubset(asset_keys):\n",
    "        return False, {\"missing\": sorted(required_common_assets - asset_keys)}\n",
    "    if any(candidate in asset_keys for candidate in primary_lst_candidates):\n",
    "        return True, None\n",
    "    missing_fallback = fallback_lst_requirements - asset_keys\n",
    "    if missing_fallback:\n",
    "        return False, {\"missing\": sorted(missing_fallback)}\n",
    "    return True, None\n",
    "\n",
    "def campus_lst_summary(landsat_item: pystac.Item, school: gpd.GeoDataFrame) -> None | CampusResult:\n",
    "    first_lst = load_landsat_lst(landsat_item, school)\n",
    "    # items, prefetched_lst_by_id= search_landsat_summers(school)\n",
    "    valid_pixels = int(np.isfinite(first_lst).sum().item())\n",
    "    mean_temp_c = float(first_lst.mean().item()) if valid_pixels else float('nan')\n",
    "    mean_temp_f = (mean_temp_c * 9 / 5 + 32) if valid_pixels else float('nan')\n",
    "\n",
    "    acquisition_dt = landsat_item.datetime\n",
    "    assert acquisition_dt is not None\n",
    "    acquisition_local = None\n",
    "    acquisition_dt = acquisition_dt.replace(tzinfo=timezone.utc)\n",
    "    acquisition_local = acquisition_dt.astimezone(ZoneInfo('America/Phoenix'))\n",
    "    return {\n",
    "        \"valid_pixels\": valid_pixels,\n",
    "        \"mean_temp_c\": mean_temp_c,\n",
    "        \"mean_temp_f\": mean_temp_f,\n",
    "        # lst_min\n",
    "        # lst_max\n",
    "        # lst_median\n",
    "        # ndvi_mean\n",
    "        \"acquisition_date\": acquisition_local,\n",
    "    }\n",
    "\n",
    "def search_landsat_summers(\n",
    "        school: gpd.GeoDataFrame,\n",
    "        start_year: int = 2015,\n",
    "        end_year: int = 2025,\n",
    "        desired_samples: int = 15,\n",
    ") -> Tuple[list[pystac.Item], dict[str, xr.DataArray]]:\n",
    "    # Search for cloud-free Landsat summer observations across multiple years\n",
    "\n",
    "    school_bounds = school.bounds.iloc[0]\n",
    "    safety_multiplier = 6\n",
    "    search_limit = max(desired_samples * safety_multiplier, 60)\n",
    "\n",
    "    summer_items = []\n",
    "    prefetched_lst_by_id = {}\n",
    "    asset_skip_log = []\n",
    "    data_skip_log = []\n",
    "\n",
    "    search_start = f\"{start_year}-06-01\"\n",
    "    search_end = f\"{end_year}-08-31\"\n",
    "\n",
    "    search = openpc.search(\n",
    "        collections=['landsat-c2-l2'],\n",
    "        bbox=expand_bounds(school_bounds),\n",
    "        datetime=f\"{search_start}/{search_end}\",\n",
    "        query={\n",
    "            'landsat:cloud_cover_land': {'eq': 0},\n",
    "            'eo:cloud_cover': {'eq': 0},\n",
    "        },\n",
    "        limit=search_limit,\n",
    "        max_items=search_limit,\n",
    "        sortby=[{'field': 'properties.datetime', 'direction': 'desc'}],\n",
    "        fields={'exclude': ['links', 'collection', 'assets.*.alternate']}\n",
    "    )\n",
    "\n",
    "    for item in search.items():\n",
    "        if item.datetime.month not in (6, 7, 8):\n",
    "            continue\n",
    "        has_assets, details = landsat_item_has_required_assets(item)\n",
    "        if not has_assets:\n",
    "            asset_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'missing_assets': details.get('missing', [])\n",
    "            })\n",
    "            continue\n",
    "        try:\n",
    "            lst_candidate = load_landsat_lst(item, school)\n",
    "        except KeyError as exc:\n",
    "            data_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'reason': f'Missing expected asset while loading LST: {exc}'\n",
    "            })\n",
    "            continue\n",
    "        except requests.exceptions.RequestException as exc:\n",
    "            data_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'reason': f'HTTP error while loading LST assets: {exc}'\n",
    "            })\n",
    "            continue\n",
    "        except rasterio.errors.RasterioError as exc:\n",
    "            data_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'reason': f'Raster read error while loading LST: {exc}'\n",
    "            })\n",
    "            continue\n",
    "        if lst_candidate is None or np.isnan(lst_candidate).all():\n",
    "            data_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'reason': 'All pixels masked or empty during prefetch validation'\n",
    "            })\n",
    "            continue\n",
    "        valid_pixels = int(np.isfinite(lst_candidate).sum().item())\n",
    "        if valid_pixels == 0:\n",
    "            data_skip_log.append({\n",
    "                'id': item.id,\n",
    "                'datetime': item.datetime.isoformat(),\n",
    "                'reason': 'No valid pixels after QA during prefetch validation'\n",
    "            })\n",
    "            continue\n",
    "        prefetched_lst_by_id[item.id] = lst_candidate\n",
    "        summer_items.append(item)\n",
    "        if len(summer_items) >= desired_samples:\n",
    "            break\n",
    "\n",
    "    if len(summer_items) < desired_samples:\n",
    "        if asset_skip_log:\n",
    "            print(\"Scenes skipped due to missing asset keys:\")\n",
    "            for entry in asset_skip_log[:10]:\n",
    "                missing_list = ', '.join(entry['missing_assets']) or 'unknown'\n",
    "                print(f\"  - {entry['id']} ({entry['datetime']}): missing {missing_list}\")\n",
    "            if len(asset_skip_log) > 10:\n",
    "                print(f\"  ...and {len(asset_skip_log) - 10} more\")\n",
    "        if data_skip_log:\n",
    "            print(\"Scenes skipped after attempting to load LST during validation:\")\n",
    "            for entry in data_skip_log[:10]:\n",
    "                print(f\"  - {entry['id']} ({entry['datetime']}): {entry['reason']}\")\n",
    "            if len(data_skip_log) > 10:\n",
    "                print(f\"  ...and {len(data_skip_log) - 10} more\")\n",
    "        raise ValueError(\n",
    "            f\"Only found {len(summer_items)} asset-complete, data-validated cloud-free summer scenes after filtering; consider relaxing filters or extending the date range.\"\n",
    "        )\n",
    "    if asset_skip_log:\n",
    "        print(f\"Skipped {len(asset_skip_log)} scenes lacking required assets before validation.\")\n",
    "    if data_skip_log:\n",
    "        print(f\"Skipped {len(data_skip_log)} scenes during data validation.\")\n",
    "    print(\n",
    "        f\"Total asset-complete, data-validated summer candidates collected (searching {end_year}→{start_year} summers): {len(summer_items)}\"\n",
    "    )\n",
    "    return summer_items, prefetched_lst_by_id\n",
    "\n",
    "def collect_summertime_lst(school: gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    summer_items, prefetched_lst_by_id = search_landsat_summers(school)\n",
    "    # return summer_items, prefetched_lst_by_id\n",
    "\n",
    "    records = []\n",
    "    skipped = []\n",
    "\n",
    "    for item in summer_items:\n",
    "        lst = prefetched_lst_by_id.get(item.id)\n",
    "        if lst is None:\n",
    "            try:\n",
    "                lst = load_landsat_lst(item, school)\n",
    "            except KeyError as exc:\n",
    "                skipped.append({'landsat_id': item.id, 'reason': f'Missing expected asset while loading LST: {exc}'})\n",
    "                continue\n",
    "            except requests.exceptions.RequestException as exc:\n",
    "                skipped.append({'landsat_id': item.id, 'reason': f'HTTP error: {exc}'})\n",
    "                continue\n",
    "            except rasterio.errors.RasterioError as exc:\n",
    "                skipped.append({'landsat_id': item.id, 'reason': f'Raster read error: {exc}'})\n",
    "                continue\n",
    "        if lst is None or np.isnan(lst).all():\n",
    "            skipped.append({'landsat_id': item.id, 'reason': 'All pixels masked or empty'})\n",
    "            continue\n",
    "        valid_pixels = int(np.isfinite(lst).sum().item())\n",
    "        if valid_pixels == 0:\n",
    "            skipped.append({'landsat_id': item.id, 'reason': 'No valid pixels after QA'})\n",
    "            continue\n",
    "        mean_temp = float(lst.mean().item())\n",
    "        median_temp = float(lst.median().item())\n",
    "        min_temp = float(lst.min().item())\n",
    "        max_temp = float(lst.max().item())\n",
    "        records.append({\n",
    "            'datetime': item.datetime,\n",
    "            'landsat_id': item.id,\n",
    "            'mean_temp_c': mean_temp,\n",
    "            'median_temp_c': median_temp,\n",
    "            'min_temp_c': min_temp,\n",
    "            'max_temp_c': max_temp,\n",
    "            'valid_pixels': valid_pixels,\n",
    "        })\n",
    "\n",
    "    if not records:\n",
    "        raise ValueError(\"No usable LST scenes were found; consider relaxing filters or expanding the search window.\")\n",
    "\n",
    "    return pd.DataFrame(records).sort_values('datetime').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cb3e8f4-f389-4981-b26c-9fd68f93020d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For this lab, we have used the [Open Street Map](https://www.openstreetmap.org/#map=5/38.01/-95.84) project to generate a list of schools in the Phoenix area. These schools were put into a [GeoJSON format](https://en.wikipedia.org/wiki/GeoJSON) and saved as a file we will use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa40b8b4-310c-4354-abe2-0170a9a6c531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load school footprints\n",
    "schools_raw = gpd.read_file(\"/Workspace/Shared/phoenix_schools.geojson\", engine=\"pyogrio\", on_invalid=\"fix\")\n",
    "# Filter and reproject\n",
    "schools_gdf = schools_raw.dropna(subset=[\"name\"])[schools_raw.geometry.type == \"Polygon\"].to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Let's see what we have\n",
    "print(f\"Total school features: {len(schools_gdf):,}\")\n",
    "schools_gdf[['name', 'amenity']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a4b486-f5b3-45df-a761-7ba4c4fb3da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now that we have a list of the schools in Phoenix, we are going to randomly select one to test the workflow. This code takes the selected school and prints out its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69cd1f04-50d1-44a1-a059-de3665ecefae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(2)  # make a deterministic generator\n",
    "school = schools_gdf.sample(1, random_state=rng)\n",
    "school_shape = school.geometry.iloc[0]\n",
    "school_bounds = school.bounds.iloc[0]\n",
    "school_centroid = school_shape.centroid\n",
    "\n",
    "print(f\"Selected school: {school.name.iloc[0]}\")\n",
    "print(f\"Location: {school_centroid.y:.5f}, {school_centroid.x:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38c7de11-4b0b-4109-9828-9f3240651557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Given the boundaries of this school, lets take a look at it on a map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "637416e5-2e3d-4121-8f04-c067e65c07f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_school_footprint(school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8194aa9-aa5b-48a1-b051-91f846168816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Microsoft's Planetary Computer [Open Data Catalog](https://planetarycomputer.microsoft.com/catalog) contains 100's of datasets about the earth all organized in a common catalog format called the Spatio Temporal Asset Catalog, or [STAC](https://stacspec.org/en/). \n",
    "\n",
    "This is where we will find the [Landsat](https://www.usgs.gov/faqs/what-landsat-satellite-program-and-why-it-important) data to measure the temperature of the various schools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6044bc-20d3-42e5-978d-f9eb33dba4a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "However, to actually look at the buildings and landscaping of these schools, we will need high-resolution aerial imagery.\n",
    "Planetary Computer hosts the [NAIP](https://planetarycomputer.microsoft.com/dataset/naip) dataset, an annual high-resolution visual dataset of the United States.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c3a19dc-717c-4a5c-9dbd-ee0d236a39d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In both cases, we need to _search_ for relevant data.\n",
    "Planetary Computer's STAC API allows us to search for STAC items by matching temporal, spatial, and/or arbitrary property filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41664497-28da-49de-b2e6-eedeead0d271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Locate NAIP and Landsat scenes covering the campus\n",
    "naip_item, landsat_candidates = collect_analysis_items(school_bounds)\n",
    "landsat_item = landsat_candidates[0]  # placeholder until data validation\n",
    "\n",
    "print(f\"NAIP item: {naip_item.id}\")\n",
    "print(f\"Initial Landsat candidate pool size: {len(landsat_candidates)} (newest first)\")\n",
    "print(f\"First candidate to validate: {landsat_item.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07857d64-ac70-424a-be43-cbd59b7a5c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### See the campus from above\n",
    "Here's the true-color NAIP scene so students can orient themselves with a familiar aerial view before diving into the analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb16ea1-42ad-4982-b3a6-2c294842d1b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_school_naip_visual(naip_item, school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "278b6ac4-4089-484d-8c5c-68f012442866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## NDVI \n",
    "The [normalized difference vegetation index](https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index) measures the presence and health of vegetation.\n",
    "\n",
    "The NAIP STAC item contain NDVI raster assets.\n",
    "We can use that band to estimate the fraction of the land area of the school that contains vegetation.\n",
    "Placing the visual and NDVI bands side-by-side, you can see that grassy and tree-lined areas are identified with NDVI values greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3df44cf-9fd5-47de-8171-4a0a28081777",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_school_naip_ndvi(naip_item, school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515555d7-5790-41f6-b987-08f80fbfb72b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clip the first Landsat candidate to the campus and summarize mean surface temperature\n",
    "campus_result = campus_lst_summary(landsat_item, school)\n",
    "assert campus_result is not None\n",
    "local_time_str = campus_result[\"acquisition_date\"].strftime('%I:%M %p %Z')\n",
    "\n",
    "print(f\"First validated Landsat scene: {landsat_item.id}\")\n",
    "print(f\"Valid pixels within campus mask: {campus_result[\"valid_pixels\"]:,}\")\n",
    "\n",
    "if campus_result[\"valid_pixels\"] > 0:\n",
    "    date_str = campus_result[\"acquisition_date\"].isoformat()\n",
    "    print(f\"Mean campus land surface temperature on {date_str} at {local_time_str}: {campus_result['mean_temp_c']:.2f} °C / {campus_result['mean_temp_f']:.2f} °F\")\n",
    "else:\n",
    "    print(\"No valid LST pixels after QA masking; check asset availability or cloud filters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd623ed5-ab8e-4a30-b6a5-381eb1b8ddf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explore multi-summer land surface temperature (LST)\n",
    "To understand seasonal variability, gather multiple cloud-free Landsat observations across several summers (June–August) and compare their campus-level land surface temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1fb79f7-5b68-4396-8dcc-79c6b6352f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summer_items, prefetched_lst_by_id = search_landsat_summers(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ddebf57-d439-4671-b55e-91b0bda41969",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the distribution of candidate scene dates\n",
    "import calendar\n",
    "\n",
    "summer_candidates_df = pd.DataFrame([\n",
    "    {\n",
    "        'datetime': item.datetime,\n",
    "        'year': item.datetime.year,\n",
    "        'month': calendar.month_abbr[item.datetime.month],\n",
    "        'day_of_year': item.datetime.timetuple().tm_yday,\n",
    "        'landsat_id': item.id,\n",
    "        'satellite': item.properties.get('landsat:platform', 'unknown').upper(),\n",
    "    }\n",
    "    for item in summer_items\n",
    "])\n",
    "\n",
    "summer_candidates_df = summer_candidates_df.sort_values('datetime').reset_index(drop=True)\n",
    "range_start = summer_candidates_df['datetime'].min()\n",
    "range_end = summer_candidates_df['datetime'].max()\n",
    "summer_candidates_df['days_since_start'] = (summer_candidates_df['datetime'] - range_start).dt.days\n",
    "total_span_days = int((range_end - range_start).days)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "scatter = ax.scatter(\n",
    "    summer_candidates_df['day_of_year'],\n",
    "    summer_candidates_df['year'],\n",
    "    c=summer_candidates_df['day_of_year'],\n",
    "    cmap='viridis',\n",
    "    s=60,\n",
    "    edgecolor='k',\n",
    "    linewidth=0.3\n",
    " )\n",
    "ax.set_title(f\"Cloud-free summer candidates for {school.name}\")\n",
    "ax.set_xlabel('Day of year')\n",
    "ax.set_ylabel('Acquisition year')\n",
    "plt.colorbar(scatter, ax=ax, label='Day of year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b671d365-f9eb-4d45-8924-ba99bcef8daa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summer_landsat_df = collect_summertime_lst(school)\n",
    "overall_mean_c = summer_landsat_df['mean_temp_c'].mean()\n",
    "print(f\"Collected {len(summer_landsat_df)} cloud-free summer observations\")\n",
    "print(f\"Overall mean LST (°C): {overall_mean_c:.2f}\")\n",
    "\n",
    "display_columns = ['datetime', 'landsat_id', 'mean_temp_c', 'median_temp_c', 'min_temp_c', 'max_temp_c', 'valid_pixels']\n",
    "summer_landsat_df[display_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3caf3fb-446c-4bf2-8e3a-64c50df1c57a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot the temperature time series to show day-to-day variability\n",
    "plot_df = summer_landsat_df.copy()\n",
    "plot_df['day_of_year'] = plot_df['datetime'].dt.dayofyear\n",
    "plot_df['year'] = plot_df['datetime'].dt.year\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "scatter = ax.scatter(\n",
    "    plot_df['day_of_year'],\n",
    "    plot_df['mean_temp_c'],\n",
    "    c=plot_df['year'],\n",
    "    cmap='viridis',\n",
    "    s=70,\n",
    "    edgecolor='k',\n",
    "    linewidth=0.4,\n",
    "    label=None\n",
    ")\n",
    "ax.axhline(overall_mean_c, color='red', linestyle='--', label=f'Overall mean = {overall_mean_c:.2f}°C')\n",
    "ax.set_title(f\"Summer Landsat LST at {school.name}\")\n",
    "ax.set_ylabel('Mean campus LST (°C)')\n",
    "ax.set_xlabel('Day of year')\n",
    "ax.grid(alpha=0.3)\n",
    "legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "if legend_handles:\n",
    "    ax.legend(loc='upper left')\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Acquisition year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7bc315-dffd-4eca-a234-627a5e7f5e01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we can repeat the analysis of mean landsurface temperature using many years of data to smooth out seasonal differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c0b360-d786-45ef-b5c5-db0633d7f2b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "records = schools_gdf.to_dict(\"records\")\n",
    "records[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1449aa3-07cd-42b0-8d9f-0e874df71bd2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1760011022052}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"mean_temp_c\", FloatType(), True),\n",
    "    StructField(\"mean_ndvi\", FloatType(), True)\n",
    "])\n",
    "gdf_serializable = schools_gdf.copy()\n",
    "gdf_serializable[\"geometry\"] = schools_gdf[\"geometry\"].to_wkt()\n",
    "rows = gdf_serializable.to_dict(\"records\")\n",
    "rdd = sc.parallelize(rows[0:10])\n",
    "\n",
    "def process(row: dict):\n",
    "    import geopandas as gpd\n",
    "    from shapely import wkt\n",
    "    import rioxarray\n",
    " \n",
    "    school = gpd.GeoDataFrame([row])\n",
    "    school[\"geometry\"] = school[\"geometry\"].apply(wkt.loads)\n",
    "    school = school.set_geometry(\"geometry\", crs=\"EPSG:4326\")\n",
    "    # school.crs = \"EPSG:4326\"\n",
    "    print(f\"Analyzing school: {school.name.iloc[0]}\")\n",
    "    naip_item, landsat_items = collect_analysis_items(school.bounds.iloc[0])\n",
    "    summertime_lst = collect_summertime_lst(school)\n",
    "    mean_temp_c = summertime_lst['mean_temp_c'].mean()\n",
    "    mean_ndvi = compute_mean_ndvi(naip_item, school)\n",
    "    return {\n",
    "        'name': school.name.iloc[0],\n",
    "        'mean_temp_c': float(mean_temp_c),\n",
    "        'mean_ndvi': float(mean_ndvi)\n",
    "    }\n",
    " \n",
    "rdd_processed = rdd.map(process).map(lambda x: Row(**x)).toDF(schema=schema)\n",
    "display(rdd_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4fb0e278-b25c-4824-9435-69d27322f5a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5953eafe-b2ea-4099-b64c-0354e1452208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO add regression and correlation coefficients, and change color of top and least 5\n",
    "schools_gdf[schools_gdf.mean_ndvi.notna()]\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(\n",
    "    schools_gdf.mean_ndvi,\n",
    "    schools_gdf.mean_temp_c,\n",
    "    alpha=0.7,\n",
    "    edgecolor='k'\n",
    ")\n",
    "plt.xlabel(\"Mean NDVI\")\n",
    "plt.ylabel(\"Mean Land Surface Temperature (°C)\")\n",
    "plt.title(\"School NDVI vs. Mean Summer Land Surface Temperature\")\n",
    "# TODO bring up the annual mean analysis instead of the point-in-time of landsat lst\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5f7782f-5488-4364-8d45-290471753034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display_school_results(schools_gdf[schools_gdf.mean_ndvi.notna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d5f99a3-fd7e-4dab-b7aa-95e3ad9928a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Visualize the top-5 hottest schools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44ccd7a-e783-41c9-8fe0-e2ad5ad1a209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top5_schools = schools_gdf[schools_gdf['mean_temp_c'].notna()].sort_values('mean_temp_c', ascending=False).head(5)\n",
    "display_columns = ['name', 'mean_temp_c', 'mean_ndvi']\n",
    "print(top5_schools[display_columns])\n",
    "for idx, row in top5_schools.iterrows():\n",
    "    school = gpd.GeoDataFrame([row], geometry='geometry', crs=schools_gdf.crs)\n",
    "    naip, _ = collect_analysis_items(school_bounds=school.bounds.iloc[0])\n",
    "    display_school_naip_ndvi(naip, school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee9ea3cf-6866-48c3-a407-8cb88475f06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And now the top 5 coolest schools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01de50e8-ff0e-4b1c-a9d0-d9d42225fc4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top5_schools = schools_gdf[schools_gdf['mean_temp_c'].notna()].sort_values('mean_temp_c').head(5)\n",
    "display_columns = ['name', 'mean_temp_c', 'mean_ndvi']\n",
    "print(top5_schools[display_columns])\n",
    "for idx, row in top5_schools.iterrows():\n",
    "    school = gpd.GeoDataFrame([row], geometry='geometry', crs=schools_gdf.crs)\n",
    "    naip, _ = collect_analysis_items(school_bounds=school.bounds.iloc[0])\n",
    "    display_school_naip_ndvi(naip, school)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b4c74db-c9e6-4693-8ca5-453b1e763135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "- Validate the NAIP + Landsat selections across different years to build a time series.\n",
    "- Compare campus-level NDVI and LST against city-wide percentiles to rank schools.\n",
    "- Persist clipped rasters or summary stats so the workshop can scale to dozens of campuses without re-querying raw imagery."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "school-greening.ipynb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "ignite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
